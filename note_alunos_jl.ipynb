{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUoiADiYrGN7"
      },
      "source": [
        "# Por que Julia?\n",
        "\n",
        "## Por que escolher Julia?\n",
        "\n",
        "-   A linguagem de programação `Julia`, lançada oficialmente em 2012, tem se destacado como uma alternativa moderna para ciência de dados e computação científica, competindo com linguagens como `Matlab`, `Python` e `R`;\n",
        "-   É utilizada não apenas na academia, [mas também fora dela.](https://ime.unicamp.br/julialang/Blog/Julia%20no%20Mercado%20de%20Trabalho.html);\n",
        "-   `Julia` é gratuita;\n",
        "-   `Julia` oferece desempenho próximo ao de C++, aliado à facilidade de aprendizado e sintaxe simples, comparáveis a `Python` e `R`;\n",
        "-   `Julia` permite escrever código com símbolos matemáticos diretamente `r emo::ji(\"nerd\")`, facilitando a expressão de conceitos científicos;\n",
        "-   `Julia` resolve o problema das duas linguagens `r emo::ji(\"cool\")`;\n",
        "-   Etc.\n",
        "\n",
        "## Do Zero ao Julia\n",
        "\n",
        "Conheça o nosso Blog!\n",
        "\n",
        "www.ime.unicamp.br/julialang"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyQxpCifTue4"
      },
      "source": [
        "# Importação de Dados\n",
        "\n",
        "Nesta seção veremos como importar nossos datasets, estando eles armazenados localmente ou online. Também veremos a diferença na leitura de diferentes formatos, como **.csv**, **.txt** e **.xlsx**.\n",
        "\n",
        "## Pacotes necessários\n",
        "\n",
        "O `Julia` conta com diversos pacotes que usamos para leitura de datasets, dentre eles vamos focar nos seguintes:\n",
        "\n",
        "``` julia\n",
        "import Pkg\n",
        "\n",
        "Pkg.add(\"DataFrames\");\n",
        "Pkg.add(\"CSV\")\n",
        "Pkg.add(\"XLSX\")\n",
        "```\n",
        "\n",
        "- `DataFrames` : Manipulação e análise de dados em formato tabular, similar ao pandas (`Python`) ou data.frame (`R`);\n",
        "- `CSV` : Leitura e escrita de arquivos CSV de forma rápida e eficiente;\n",
        "- `XLSX` : Leitura e escrita de arquivos Excel (.xlsx).\n",
        "\n",
        "## Funções básicas\n",
        "\n",
        "Com os pacotes necessários instalados, agora vejamos como as funções de leitura funcionam:\n",
        "\n",
        "``` julia\n",
        "using DataFrames, CSV, XLSX\n",
        "\n",
        "# .csv\n",
        "\n",
        "df_csv = CSV.read(\"caminho/dados.csv\", DataFrame)\n",
        "\n",
        "# .txt\n",
        "\n",
        "df_txt = CSV.read(\"caminho/dados.txt\", DataFrame, delim=';')\n",
        "\n",
        "# .xlsx\n",
        "\n",
        "sheets = XLSX.readxlsx(\"caminho/dados.xlsx\")\n",
        "df_xlsx = DataFrame(sheets)\n",
        "```\n",
        "\n",
        "## Funções básicas\n",
        "\n",
        "Podemos usar a função `download()` é usada para baixar um arquivo temporariamente e retorna o caminho local onde ele foi salvo.\n",
        "\n",
        "**Ex.:**\n",
        "\n",
        "``` julia\n",
        "using DataFrames\n",
        "\n",
        "dados_csv = CSV.read(download(url), DataFrame, delim=';')\n",
        "\n",
        "first(dados_csv, 5) # Podemos usar a função first() para visualizar as primeiras linhas do dataset\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yRJeUxqDjsp"
      },
      "source": [
        "## Importação dos pacotes\n",
        "\n",
        "Agora, vamos botar a mão na massa e ler os dados que usaremos na aula de hoje!\n",
        "\n",
        "Primeiramente, faremos a importação de todos os pacotes que usaremos ao longo do código.\n",
        "\n",
        "Essa é uma prática recomendada quando o projeto já foi inteiramente desenvolvido e já sabemos de quais pacotes precisaremos.\n",
        "\n",
        "Vale ressaltar que, apesar de esse ser nosso primeiro bloco (por motivos de praticidade e otimização de tempo no minicurso), na prática, essa é a última etapa feita.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "sX6EJbwbE18B",
        "outputId": "34014f88-b0f6-4356-9a8d-fb07984116bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General.toml`\n",
            "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
            "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.11/Project.toml`\n",
            "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.11/Manifest.toml`\n",
            "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
            "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.11/Project.toml`\n",
            "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.11/Manifest.toml`\n",
            "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
            "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.11/Project.toml`\n",
            "  \u001b[90m[2913bbd2] \u001b[39m\u001b[92m+ StatsBase v0.34.6\u001b[39m\n",
            "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.11/Manifest.toml`\n",
            "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
            "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.11/Project.toml`\n",
            "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.11/Manifest.toml`\n",
            "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m ShiftedArrays ─ v2.0.0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Chain ───────── v0.6.0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Cleaner ─────── v1.1.1\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m TidierData ──── v0.17.0\n",
            "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.11/Project.toml`\n",
            "  \u001b[90m[fe2206b3] \u001b[39m\u001b[92m+ TidierData v0.17.0\u001b[39m\n",
            "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.11/Manifest.toml`\n",
            "\u001b[33m⌅\u001b[39m \u001b[90m[8be319e6] \u001b[39m\u001b[92m+ Chain v0.6.0\u001b[39m\n",
            "  \u001b[90m[caabdcdb] \u001b[39m\u001b[92m+ Cleaner v1.1.1\u001b[39m\n",
            "  \u001b[90m[1277b4bf] \u001b[39m\u001b[92m+ ShiftedArrays v2.0.0\u001b[39m\n",
            "  \u001b[90m[fe2206b3] \u001b[39m\u001b[92m+ TidierData v0.17.0\u001b[39m\n",
            "\u001b[36m\u001b[1m        Info\u001b[22m\u001b[39m Packages marked with \u001b[33m⌅\u001b[39m have new versions available but compatibility constraints restrict them from upgrading. To see why use `status --outdated -m`\n",
            "\u001b[92m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
            "   1499.6 ms\u001b[32m  ✓ \u001b[39m\u001b[90mChain\u001b[39m\n",
            "   1531.9 ms\u001b[32m  ✓ \u001b[39m\u001b[90mShiftedArrays\u001b[39m\n",
            "   5867.4 ms\u001b[32m  ✓ \u001b[39m\u001b[90mCleaner\u001b[39m\n",
            "   3774.2 ms\u001b[32m  ✓ \u001b[39mTidierData\n",
            "  4 dependencies successfully precompiled in 11 seconds. 496 already precompiled.\n",
            "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Distances ───────── v0.10.12\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m ADTypes ─────────── v1.17.0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Widgets ─────────── v0.6.7\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m NearestNeighbors ── v0.4.22\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m MultivariateStats ─ v0.10.3\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Arpack_jll ──────── v3.5.1+1\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Arpack ──────────── v0.5.4\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m StatsPlots ──────── v0.15.7\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m TableOperations ─── v1.2.0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Interpolations ──── v0.15.1\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Clustering ──────── v0.15.8\n",
            "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.11/Project.toml`\n",
            "  \u001b[90m[f3b207a7] \u001b[39m\u001b[92m+ StatsPlots v0.15.7\u001b[39m\n",
            "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.11/Manifest.toml`\n",
            "  \u001b[90m[47edcb42] \u001b[39m\u001b[93m↑ ADTypes v1.16.0 ⇒ v1.17.0\u001b[39m\n",
            "  \u001b[90m[7d9fca2a] \u001b[39m\u001b[92m+ Arpack v0.5.4\u001b[39m\n",
            "  \u001b[90m[aaaa29a8] \u001b[39m\u001b[92m+ Clustering v0.15.8\u001b[39m\n",
            "  \u001b[90m[b4f34e82] \u001b[39m\u001b[92m+ Distances v0.10.12\u001b[39m\n",
            "\u001b[33m⌅\u001b[39m \u001b[90m[a98d9a8b] \u001b[39m\u001b[95m↓ Interpolations v0.16.1 ⇒ v0.15.1\u001b[39m\n",
            "  \u001b[90m[6f286f6a] \u001b[39m\u001b[92m+ MultivariateStats v0.10.3\u001b[39m\n",
            "  \u001b[90m[b8a86587] \u001b[39m\u001b[92m+ NearestNeighbors v0.4.22\u001b[39m\n",
            "  \u001b[90m[f3b207a7] \u001b[39m\u001b[92m+ StatsPlots v0.15.7\u001b[39m\n",
            "  \u001b[90m[ab02a1b2] \u001b[39m\u001b[92m+ TableOperations v1.2.0\u001b[39m\n",
            "  \u001b[90m[cc8bc4a8] \u001b[39m\u001b[92m+ Widgets v0.6.7\u001b[39m\n",
            "\u001b[33m⌅\u001b[39m \u001b[90m[68821587] \u001b[39m\u001b[92m+ Arpack_jll v3.5.1+1\u001b[39m\n",
            "\u001b[36m\u001b[1m        Info\u001b[22m\u001b[39m Packages marked with \u001b[33m⌅\u001b[39m have new versions available but compatibility constraints restrict them from upgrading. To see why use `status --outdated -m`\n",
            "\u001b[92m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
            "   2245.8 ms\u001b[32m  ✓ \u001b[39m\u001b[90mADTypes\u001b[39m\n",
            "   2121.0 ms\u001b[32m  ✓ \u001b[39m\u001b[90mTableOperations\u001b[39m\n",
            "   2435.3 ms\u001b[32m  ✓ \u001b[39m\u001b[90mDistances\u001b[39m\n",
            "   1571.6 ms\u001b[32m  ✓ \u001b[39m\u001b[90mArpack_jll\u001b[39m\n",
            "   2324.2 ms\u001b[32m  ✓ \u001b[39m\u001b[90mWidgets\u001b[39m\n",
            "   1407.0 ms\u001b[32m  ✓ \u001b[39m\u001b[90mADTypes → ADTypesChainRulesCoreExt\u001b[39m\n",
            "   1236.0 ms\u001b[32m  ✓ \u001b[39m\u001b[90mADTypes → ADTypesEnzymeCoreExt\u001b[39m\n",
            "   1002.5 ms\u001b[32m  ✓ \u001b[39m\u001b[90mADTypes → ADTypesConstructionBaseExt\u001b[39m\n",
            "   2324.3 ms\u001b[32m  ✓ \u001b[39m\u001b[90mDistances → DistancesSparseArraysExt\u001b[39m\n",
            "   7146.1 ms\u001b[32m  ✓ \u001b[39m\u001b[90mInterpolations\u001b[39m\n",
            "   1965.0 ms\u001b[32m  ✓ \u001b[39m\u001b[90mDistances → DistancesChainRulesCoreExt\u001b[39m\n",
            "   1923.2 ms\u001b[32m  ✓ \u001b[39m\u001b[90mArpack\u001b[39m\n",
            "   3747.5 ms\u001b[32m  ✓ \u001b[39m\u001b[90mInterpolations → InterpolationsUnitfulExt\u001b[39m\n",
            "   9296.2 ms\u001b[32m  ✓ \u001b[39m\u001b[90mNearestNeighbors\u001b[39m\n",
            "   5241.3 ms\u001b[32m  ✓ \u001b[39m\u001b[90mMultivariateStats\u001b[39m\n",
            "   5657.2 ms\u001b[32m  ✓ \u001b[39m\u001b[90mKernelDensity\u001b[39m\n",
            "   5997.0 ms\u001b[32m  ✓ \u001b[39m\u001b[90mClustering\u001b[39m\n",
            "  29000.4 ms\u001b[32m  ✓ \u001b[39mLux\n",
            "  10260.3 ms\u001b[32m  ✓ \u001b[39mLux → LuxEnzymeExt\n",
            "  22954.7 ms\u001b[32m  ✓ \u001b[39mStatsPlots\n",
            "  18266.2 ms\u001b[32m  ✓ \u001b[39mLux → LuxReactantExt\n"
          ]
        }
      ],
      "source": [
        "import Pkg\n",
        "Pkg.add(\"CSV\")\n",
        "Pkg.add(\"DataFrames\")\n",
        "Pkg.add(\"StatsBase\")\n",
        "Pkg.add(\"Plots\")\n",
        "Pkg.add(\"TidierData\")\n",
        "Pkg.add(\"StatsPlots\")\n",
        "Pkg.add(\"MLJ\")\n",
        "Pkg.add(\"CategoricalArrays\")\n",
        "Pkg.add(\"GLM\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoethl4dUAsN"
      },
      "source": [
        "## Leitura da base de dados\n",
        "\n",
        "Agora, vamos botar a mão na massa e ler os dados que usaremos na aula de hoje!\n",
        "\n",
        "- **Exercício 1**\n",
        "  - **1.1** Escreva o código para o ler o dataset vindo da url abaixo.\n",
        "  - **1.2** Visualize as primeiras 10 linhas do seu dataset.\n",
        "  \n",
        "\n",
        "`https://raw.githubusercontent.com/Arthur-Dionizio/minicurso-julia/main/datasets/dataset.csv`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Escreva seu código aqui"
      ],
      "metadata": {
        "id": "dUSjJVCW2xl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODSVXrdqVmb4"
      },
      "source": [
        "# Banco de dados\n",
        "\n",
        "## Dados de faixas do Spotify\n",
        "\n",
        "Vamos analisar um banco de dados de faixas do Spotify abrangendo 125 gêneros diferentes. Aqui estão as principais colunas do dataset:\n",
        "\n",
        "1. **`track_id`**: O ID do Spotify para a faixa.\n",
        "\n",
        "2. **`artists`**: Os nomes dos artistas que interpretaram a faixa. Se houver mais de um artista, eles serão separados por \";\" ;\n",
        "\n",
        "3. **`album_name`**: O nome do álbum de onde a faixa pertence;\n",
        "\n",
        "4. **`track_name`**: Nome da faixa;\n",
        "\n",
        "5. **`popularity`**: A popularidade de uma faixa é um valor entre 0 e 100, sendo 100 o mais popular, sendo calculada a partir (de forma geral) do número de streams daquela faixa, e o quão recente foram essas streams;\n",
        "\n",
        "6. **`duration_ms`**: A duração da faixa em milissegundos;\n",
        "\n",
        "7. **`explicit`**: Indica se a faixa contém letras explícitas (`true` = sim, contém; `false` = não contém ou desconhecido);\n",
        "\n",
        "8. **`danceability`**: A dançabilidade descreve o quão adequada uma faixa é para dançar com base em uma combinação de elementos musicais, incluindo andamento, estabilidade do ritmo, força da batida e regularidade geral. Um valor de 0,0 é o menos dançante e 1,0 o mais dançante;\n",
        "\n",
        "9. **`energy`**: Energia é uma medida de 0,0 a 1,0 e representa uma medida perceptual de intensidade e atividade. Normalmente, músicas energéticas parecem rápidas, altas e barulhentas. Por exemplo, o death metal tem alta energia, enquanto um prelúdio de Bach tem baixa pontuação na escala;\n",
        "\n",
        "10. **`key`**: A tonalidade em que a faixa está. Os inteiros mapeiam para notas usando a notação de classe de alturas padrão (*Pitch Class*). Se nenhuma tonalidade for detectada, o valor é -1;\n",
        "\n",
        "11. **`loudness`**: O volume total de uma faixa em decibéis (dB);\n",
        "\n",
        "12. **`mode`**: O modo indica a modalidade (maior ou menor) de uma faixa, ou seja, o tipo de escala a partir da qual seu conteúdo melódico é derivado. O modo maior é representado por 1 e o menor por 0;\n",
        "\n",
        "13. **`speechiness`**: Detecta a presença de palavras faladas em uma faixa. Quanto mais exclusivamente semelhante à fala for a gravação (por exemplo, talk show, audiolivro, poesia), mais próximo de 1,0 será o valor do atributo. Valores acima de 0,66 descrevem faixas que provavelmente são compostas inteiramente de palavras faladas. Valores entre 0,33 e 0,66 descrevem faixas que podem conter música e fala, seja em seções ou em camadas, incluindo casos como rap. Valores abaixo de 0,33 provavelmente representam música e outras faixas que não se assemelham à fala;\n",
        "\n",
        "14. **`acousticness`**: Uma medida de confiança de 0,0 a 1,0 para determinar se a faixa é acústica. 1,0 representa alta confiança de que a faixa é acústica;\n",
        "\n",
        "15. **`valence`**: Uma medida de 0,0 a 1,0 que descreve a positividade musical transmitida por uma faixa. Faixas com alta valência soam mais positivas (por exemplo, felizes, alegres, eufóricas), enquanto faixas com baixa valência soam mais negativas (por exemplo, tristes, deprimidas, raivosas);\n",
        "\n",
        "16. **`tempo`**: O andamento estimado geral de uma faixa em batidas por minuto (BPM);\n",
        "\n",
        "17. **`track_genre`**: O gênero da faixa;\n",
        "\n",
        "18. **`instrumentalness`**: Prevê se uma faixa não contém vocais. Sons de \"Ooh\" e \"aah\" são tratados como instrumentais neste contexto. Faixas de rap ou palavra falada são claramente \"vocais\". Quanto mais próximo o valor de instrumentalidade estiver de 1,0, maior a probabilidade de a faixa não conter conteúdo vocal;\n",
        "\n",
        "19. **`liveness`**: Detecta a presença de público na gravação. Valores mais altos de ao vivo representam uma probabilidade maior de que a faixa tenha sido tocada ao vivo. Um valor acima de 0,8 fornece alta probabilidade de que a faixa seja ao vivo;\n",
        "\n",
        "20. **`time_signature`**: Fórmula de compasso estimada. O compasso é uma convenção de notação que especifica quantas batidas há em cada compasso. O valor varia de 3 a 7, representando compassos de 3/4 até 7/4."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doWovvU5VvgK"
      },
      "source": [
        "# Manipulação de banco de dados\n",
        "\n",
        "Agora que temos o nosso dataset, vamos passar por algumas funções e pacotes que vão nos auxiliar na limpeza dos nossos dados!\n",
        "\n",
        "## Tidier.jl\n",
        "\n",
        "A biblioteca `Tidier.jl` possui vários pacotes que auxiliam na manipulação e análise de datasets. Para quem está vindo do `R`, esses pacotes são bem similares e intuitivos. Aqui estão alguns dos pacotes:\n",
        "\n",
        "- **`TidierData`** : Implementação 100% `Julia` dos pacotes `dplyr` e `tidyr` do `R`. Usado na tranformação e manipulação dos dados;\n",
        "- **`TidierPlots`** : Implementação 100% `Julia` do pacote `ggplot2` do `R`;\n",
        "- **`TidierStrings`** : O objetivo deste pacote é replicar o `stringr` do `R` em `Julia` de uma forma que funcione com o Tidier ou como uma função autônoma.\n",
        "\n",
        "> Para saber mais sobre o uso do pacote Tidier.jl e suas funcionalidades, consulte a [documentação oficial](https://tidierorg.github.io/Tidier.jl/v1.6.1/) e o [artigo do blog do IMECC/Unicamp](https://ime.unicamp.br/julialang/Blog/tidierdata.html).\n",
        "\n",
        "## Pacote TidierData.jl\n",
        "\n",
        "Para a nossa análise de hoje, vamos utilizar principalmente o pacote `TidierData`.\n",
        "\n",
        "### Funções Macro\n",
        "\n",
        "Para suportar a programação no estilo `R`, o `TidierData.jl` é implementado usando **macros**. Isso ocorre porque as **macros** são capazes de \"capturar\" o código antes de executá-lo, o que permite que o pacote suporte \"expressões *tidy*\" semelhantes ao `R` que, de outra forma, não seriam consideradas código `Julia` válido."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-u8BiQsNWX5P"
      },
      "outputs": [],
      "source": [
        "# Não será necessário rodar esse código, pois já fizemos a importação de todos os pacotes logo no início do código!\n",
        "\n",
        "\"\"\"import Pkg\n",
        "\n",
        "Pkg.add(\"TidierData\")\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNErr1OdWK4D"
      },
      "outputs": [],
      "source": [
        "using TidierData\n",
        "\n",
        "@chain df begin\n",
        "    @filter(popularity > 50)\n",
        "    @arrange(desc(\"energy\"))\n",
        "    @select(track_name, popularity, energy, acousticness)\n",
        "    @slice(1:5)\n",
        "end"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2xw2e_CWoRZ"
      },
      "source": [
        "- Para quem já está familiarizado com a linguagem `R`, a função `@chain()` é similar ao pipeline `%>%` ou `|>`, usado para encadear várias operações em sequência no mesmo conjunto de dados.\n",
        "\n",
        "    - `@filter()` : Filtra as linhas com base em uma restrição;\n",
        "    - `@arrange()` : Ordena as linhas com base em uma coluna (`desc()` para definir ordem crescente ou decrescente);\n",
        "    - `@select()` : Seleciona as colunas de interesse;\n",
        "    - `@slice()` : Seleciona as linhas para visualização.\n",
        "\n",
        "> Obs.: A função `desc()` é uma função auxiliar.\n",
        "\n",
        "---\n",
        "\n",
        "### Funções auxiliares\n",
        "\n",
        "Algumas funções auxiliares do pacote que é importante citarmos:\n",
        "\n",
        "- `across()` : Aplica uma função a várias colunas de uma vez;\n",
        "- `n()` e `row_number()` : Retornam o número total de linhas ou o número da linha;\n",
        "- `replace_missing()` : Substitui valores ausentes em uma coluna por um valor especificado.\n",
        "\n",
        "Outras funções auxiliares do pacote DataFrames.jl e da base do `Julia` que vale mencionar:\n",
        "\n",
        "- `dropmissing()` : Remove as linhas que contêm valores faltantes (*missing*);\n",
        "- `unique()` : Retorna os valores distintos únicos de um vetor ou coluna, removendo duplicatas;\n",
        "- `nrow()` : Retorna o número de linhas de um DataFrame ou matriz;\n",
        "- `any()` : Testa se **pelo menos um** elemento de uma coleção (ou resultado de uma condição) é verdadeiro; retorna `true` ou `false`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_6L9keWW4AX"
      },
      "source": [
        "## Limpeza de dados: Tratando valores faltantes\n",
        "\n",
        "- **Exercício 2**\n",
        "  - **2.1** Verifique quantas linhas possuem `missing` em alguma coluna.\n",
        "  - **2.2** Retire essas linhas do dataset.\n",
        "\n",
        "> Dica: Use a função `any()` e a função `ismissing` no formato `row -> any(ismissing, row)` para verificar se há colunas sem informação. Nesse caso, a função `filter()` da base do `Julia` é mais eficiente, no formato `filter(condição, dados)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hPqfqUFXdgn"
      },
      "outputs": [],
      "source": [
        "# Escreva seu código aqui"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obs: Caso queira conferir o tipo dos dados de cada coluna, utilize:"
      ],
      "metadata": {
        "id": "mzz2kiBuPTRY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# eltype.(eachcol(df))"
      ],
      "metadata": {
        "id": "xawxG9NsPcm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgOOJ7XRX0ML"
      },
      "source": [
        "## Limpeza de dados: Tratando valores duplicados\n",
        "\n",
        "Agora sem valores faltantes, vamos verificar faixas duplicadas.\n",
        "\n",
        "- **Exercício 3**\n",
        "  - **3.1** Verifique quantas faixas duplicadas tem no dataset (filtre pelo `track_id`).\n",
        "  - **3.2** Retire as faixas duplicadas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxo4YKDcYP8v"
      },
      "outputs": [],
      "source": [
        "# Escreva seu código aqui"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf-HgZXz7mSV"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcmjYsF4rGOH"
      },
      "source": [
        "# Análise Exploratória dos Dados (EDA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rYZF4cJpnZQ"
      },
      "source": [
        "Nesta etapa, exploramos as variáveis do dataset para entender a distribuição dos dados, identificar padrões e obter insights iniciais.\n",
        "\n",
        "**`Statistics.jl`**: Biblioteca padrão do Julia que oferece funções estatísticas básicas, como média (mean), mediana (median), variância (var), desvio-padrão (std), entre outras.\n",
        "\n",
        "**`StatsBase.jl`**: Complementa o pacote Statistics com funções estatísticas adicionais, como countmap (para criar tabelas de frequência), cálculo de quantis, amostragem aleatória e medidas de dispersão.\n",
        "\n",
        "**`Plots.jl`**: Biblioteca versátil de criação de gráficos, permitindo gerar diferentes tipos de visualizações de forma simples e customizável.\n",
        "\n",
        "**`StatsPlots.jl`**: Extensão do Plots.jl que integra funcionalidades estatísticas, permitindo criar gráficos como boxplots, violin plots e heatmaps diretamente a partir de DataFrames.\n",
        "\n",
        "> Para aprender mais sobre a criação de gráficos no Julia, acesse o tutorial oficial disponível no site do [IMECC/Unicamp: Gráficos básicos em Julia](https://ime.unicamp.br/julialang/Tutoriais/graf_basico.html).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiQJoXCer4Y6"
      },
      "source": [
        "## EDA: Gerando estatísticas descritivas\n",
        "Nesta etapa, utilizaremos funções básicas dos pacotes Statistics, StatsPlots e Plots para explorar e resumir o conjunto de dados.\n",
        "\n",
        "- **Exercício 4**\n",
        "  - **4.1** Importe as bibliotecas mencionadas acima para habilitar o cálculo de medidas estatísticas e a criação de visualizações.\n",
        "  - **4.2** Identifique e liste os cinco (5) artistas com maior número de faixas no dataset, ou seja, aqueles mais presentes na base de dados — lembrando que isso não implica necessariamente que sejam os mais populares.\n",
        "  - **4.3** Obtenha as estatísticas descritivas das variáveis numéricas referentes ao artista com o maior número de faixas no dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjdZqwJWs2Pq"
      },
      "outputs": [],
      "source": [
        "# Escreva seu código aqui"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4NIVuM1rGOH"
      },
      "source": [
        "## EDA: Gerando gráficos descritivos\n",
        "- **Exercício 5**\n",
        "  - **5.1** Converta a variável `duration_ms`, que está em milissegundos, para minutos utilizando o operador de divisão elemento a elemento ./. Nomeie a nova coluna como `duration_min`.\n",
        "> Dica: 1 minuto equivale a 60.000 milissegundos.\n",
        "\n",
        "  - **5.2** Crie um histograma representando o tempo de duração das músicas em minutos. Analise o gráfico e identifique em qual intervalo de tempo a duração é predominante.\n",
        "\n",
        "  - **5.3** Gere o gráfico da curva de densidade para a variável `duration_min`, permitindo observar a distribuição de forma suavizada.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PCquHrGc7vNa"
      },
      "outputs": [],
      "source": [
        "# Escreva seu código aqui"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQGe749U-yXJ"
      },
      "source": [
        "## EDA: Medidas de correlação\n",
        "* A correlação é uma medida estatística que descreve a força e a direção do relacionamento linear entre duas variáveis quantitativas.\n",
        "O coeficiente de correlação, r, varia entre -1 e 1:\n",
        "\n",
        "  - indica correlação positiva perfeita,\n",
        "\n",
        "  - -1 indica correlação negativa perfeita,\n",
        "\n",
        "  - 0 indica ausência de correlação.\n",
        "\n",
        "Uma correlação positiva significa que, à medida que uma variável aumenta, a outra também tende a aumentar.\n",
        "Já uma correlação negativa significa que, à medida que uma variável aumenta, a outra tende a diminuir."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wV12Y_jarGOI"
      },
      "source": [
        "- **Exercício 6**\n",
        "  - **6.1** Separe as colunas do dataframe em `var_numericas` e `var_categoricas`.\n",
        "  - Exemplo:\n",
        "    ``` julia\n",
        "    var_numericas = [:popularity, :duration_ms]\n",
        "    var_discretas = [:track_genre, :track_id]\n",
        "    ```\n",
        "\n",
        "  - **6.2** Gere uma nova tabela, derivada da tabela original, com apenas as variáveis numéricas. Chame essa nova tabela de `numdf`.\n",
        "  - **6.3** Usando `cor(Matrix())`, faça uma matriz de correlação com as variáveis de `numdf`.\n",
        "\n",
        "  - **6.4** Plote-a usando a função `heatmap()`. Quais variáveis se relacionam mais e quais se relacionam menos?\n",
        "> Dica: a função `heatmap()` recebe valores tridimensionais. Converta a variável `var_numericas` para `String` e relacione com a matriz de correlação.\n",
        "\n",
        "  - **6.5** Gere também uma outra tabela `X`, que conterá apenas as colunas numéricas e categóricas que usaremos em nosso modelo, e separe nossa variável resposta numa variável `Y` isolada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vxIX5fmrGOI"
      },
      "outputs": [],
      "source": [
        "# Escreva seu código aqui"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wTvY7E4-XFzY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X = select(df, union(?, ?))\n",
        "# y = df.variavel_resposta"
      ],
      "metadata": {
        "id": "I0ul6bg9UNNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  - Para verificar se deu certo, rode uma célula contendo apenas `X` e uma contendo apenas `y`\n",
        "  - Para rodas ambos na mesma célula, você deve utilizar a função `display()`. Por padrão, Julia exibe somente o último objeto da célula"
      ],
      "metadata": {
        "id": "sUinjYYc1e-x"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dl2b9TO41iuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0kZmNTkZ1jAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pré-processamento"
      ],
      "metadata": {
        "id": "qVcjjzCXp7rc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pré-processamento: Divisão do dataset em dataset de treino e dataset de teste"
      ],
      "metadata": {
        "id": "gzNxXhXrfjPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "using MLJ\n",
        "# Substitua o parâmetro ? pela porcentagem (em decimal) do dataset total que você deseja designar para\n",
        "# treino. O Restante ficará para com dataset de teste.\n",
        "train_idx, test_idx = partition(collect(eachindex(y)), ?, shuffle=true, rng=42)\n",
        "\n",
        "X_train = X[train_idx, :]\n",
        "X_test  = X[test_idx, :]\n",
        "y_train = y[train_idx]\n",
        "y_test  = y[test_idx]"
      ],
      "metadata": {
        "id": "53u3z_amfrOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbqlKmZvrGOI"
      },
      "source": [
        "## Pré-processamento: Normalização das variáveis numéricas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# verificando as colunas numéricas:\n",
        "describe(df[:, var_numericas], :min, :max)"
      ],
      "metadata": {
        "id": "hKdmdmee422S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "using MLJ\n",
        "using StatsBase"
      ],
      "metadata": {
        "id": "IKPEjPa65EKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Normalização das colunas contínuas ---\n",
        "X_train_scaled = deepcopy(X_train)\n",
        "X_test_scaled  = deepcopy(X_test)\n",
        "\n",
        "for col in var_numericas\n",
        "    x_train = Float64.(X_train[!, col])\n",
        "    scaler = fit(UnitRangeTransform, x_train)\n",
        "\n",
        "    X_train_scaled[!, col] = StatsBase.transform(scaler, x_train)\n",
        "    X_test_scaled[!, col]  = StatsBase.transform(scaler, Float64.(X_test[!, col]))\n",
        "end\n",
        "\n",
        "# colunas categóricas permanecem inalteradas\n",
        "\n",
        "# Ver resumo estatístico das colunas numéricas\n",
        "describe(X_train_scaled[:, var_numericas])"
      ],
      "metadata": {
        "id": "ZKup3Ec25GQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizar as primeiras 5 linhas do df original para comparar\n",
        "first(X, 5)"
      ],
      "metadata": {
        "id": "KN95ImcU5Kia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizar as primeiras 5 linhas do df normalizado para comparar\n",
        "first(X_train_scaled, 5)"
      ],
      "metadata": {
        "id": "ewEYNgVn5NAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ver resumo estatístico das colunas numéricas\n",
        "describe(df[:, var_numericas])"
      ],
      "metadata": {
        "id": "x7upOSfq5QRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pré-processamento: Encoding das variáveis categóricas\n",
        "\n",
        "  - Aplicar one hot encoding em variáveis categóricas é uma técnica comum para converter essas variáveis em um formato que pode ser usado por algoritmos de aprendizado de máquina.\n",
        "  - Isso envolve criar colunas binárias para cada categoria, permitindo que o modelo aprenda a partir dessas variáveis categóricas de forma mais eficaz.\n",
        "  - Essa técnica é essencial em modelos como regressão linear, árvores de decisão e redes neurais, onde as variáveis categóricas precisam ser representadas numericamente."
      ],
      "metadata": {
        "id": "NbacbZ6vgrGf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "using CategoricalArrays, MLJ\n",
        "\n",
        "# --- converter colunas de string para categóricas (apenas nas features) ---\n",
        "for col in names(X_train_scaled)\n",
        "    if eltype(X_train_scaled[!, col]) <: AbstractString\n",
        "        X_train_scaled[!, col] = categorical(X_train_scaled[!, col])\n",
        "        X_test_scaled[!, col]  = categorical(X_test_scaled[!, col])\n",
        "    end\n",
        "end\n",
        "\n",
        "# --- One-Hot Encoder (ajusta no treino, transforma treino e teste) ---\n",
        "ohe = OneHotEncoder(drop_last=true)  # drop_last evita multicolinearidade para GLM\n",
        "\n",
        "mach_ohe = MLJ.machine(ohe, X_train_scaled)\n",
        "MLJ.fit!(mach_ohe)\n",
        "\n",
        "X_train_cleaned = MLJ.transform(mach_ohe, X_train_scaled)\n",
        "X_test_cleaned  = MLJ.transform(mach_ohe, X_test_scaled)\n",
        "\n",
        "\n",
        "X_train_cleaned\n"
      ],
      "metadata": {
        "id": "KKum6w_9gr1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "typeof(X_train_cleaned)\n"
      ],
      "metadata": {
        "id": "mZeNaJvJ58qB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pré-processamento: Transformar o df em matriz\n",
        "\n",
        "  - Essa técnica é essencial para modelos de Regressão Linear Múltipla\n",
        "\n",
        "  - `Float64.(Matrix(X_train_cleaned))` garante que todas as colunas sejam numéricas, requisito do `GLM.jl`, o pacote que usaremos para implementar nossa Reg. Lin. Múltipla.\n",
        "\n",
        "  - Nesse pacote, quando temos múltiplas features, podemos usar a forma matricial `(X e y)` ou transformar `X_train_cleaned` em `DataFrame` com colunas nomeadas para usar fórmula.\n",
        "\n",
        "  - Faremos uso da abordagem matricial, que funciona diretamente com `DataFrame` ou `Matrix`."
      ],
      "metadata": {
        "id": "p7-HEQtshhs_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  - A função abaixo serve para retornar o tipo de dado de algum objeto. Em outras palavras:\n",
        "\n",
        "  - - Ela não mostra o conteúdo da variável.\n",
        "\n",
        "  - - Ela diz de que “classe” ou estrutura interna o objeto é, por exemplo: `DataFrame`, `Matrix{Float64}`, `CategoricalArray{String,1,UInt32}`, etc."
      ],
      "metadata": {
        "id": "Zal60TIokti2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_mat = Matrix(X_train_cleaned)\n",
        "display(typeof(X_train_mat))\n",
        "\n",
        "X_test_mat = Matrix(X_test_cleaned)\n",
        "display(typeof(X_test_mat))\n",
        "\n",
        "X_train_mat\n"
      ],
      "metadata": {
        "id": "leYpC231hg-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  - Vetorização da variável resposta (*target variable*), `energy`:"
      ],
      "metadata": {
        "id": "7ECeu9ocnbZd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_vec = y_train\n",
        "y_test_vec  = y_test"
      ],
      "metadata": {
        "id": "GdmAB9iJnaLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelagem"
      ],
      "metadata": {
        "id": "Bfl1W0m1lcGQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  - Durante a etapa de modelagem, segue-se o seguinte fluxo:\n",
        "\n",
        "  - **1.** Escolha de um algoritmo ou técnica\n",
        "\n",
        "  - - Ex.: regressão linear, árvores de decisão, redes neurais, SVM etc.\n",
        "  - - Essa escolha depende do tipo de problema (classificação, regressão, clustering, etc.) e das características dos dados.\n",
        "\n",
        "  - **2.** Treinamento do modelo\n",
        "\n",
        "  - - Alimentamos o algoritmo com os dados de treino.\n",
        "\n",
        "  - - O modelo ajusta seus parâmetros internos para minimizar um erro ou maximizar um desempenho (função de custo/objetivo).\n",
        "\n",
        "  - **3.** Validação e ajuste\n",
        "\n",
        "  - - Utilização dos dados de validação para verificar se o modelo está generalizando bem (tendo bom desempenho nos dados de teste).\n",
        "\n",
        "  - - Ajuste dos hiperparâmetros (ex.: profundidade da árvore, taxa de aprendizado, número de neurônios).\n",
        "\n",
        "  - **(Opcional) 4.** Comparação de modelos diferentes\n",
        "\n",
        "  - - Treina-se vários algoritmos e compara métricas (ex.: acurácia, precisão, recall, RMSE).\n",
        "\n",
        "  - - Escolhe-se aquele com melhor equilíbrio entre desempenho e simplicidade."
      ],
      "metadata": {
        "id": "aibH1uGDloBG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "using GLM, Statistics\n",
        "\n",
        "\"\"\"\n",
        "Treina um modelo de regressão linear múltipla e calcula métricas de avaliação.\n",
        "Retorna um NamedTuple com o modelo e as métricas.\n",
        "\"\"\"\n",
        "function train_linear_regression(X_train, y_train, X_test, y_test)\n",
        "    # Ajustar modelo\n",
        "    model = lm(X_train_mat, y_train_vec)\n",
        "\n",
        "    # Predições\n",
        "    y_pred_train = GLM.predict(model, X_train_mat)\n",
        "    y_pred_test  = GLM.predict(model, X_test_mat)\n",
        "\n",
        "    # Métricas\n",
        "    r2_train = 1 - sum((y_train_vec - y_pred_train).^2) / sum((y_train_vec .- mean(y_train_vec)).^2)\n",
        "    r2_test  = 1 - sum((y_test_vec - y_pred_test).^2) / sum((y_test_vec .- mean(y_test_vec)).^2)\n",
        "\n",
        "    rmse_train = sqrt(mean((y_train_vec - y_pred_train).^2))\n",
        "    rmse_test  = sqrt(mean((y_test_vec - y_pred_test).^2))\n",
        "\n",
        "    return (\n",
        "        model       = model,\n",
        "        r2_train    = r2_train,\n",
        "        r2_test     = r2_test,\n",
        "        rmse_train  = rmse_train,\n",
        "        rmse_test   = rmse_test\n",
        "    )\n",
        "end"
      ],
      "metadata": {
        "id": "Uknrlqn-lbhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = train_linear_regression(X_train_cleaned, y_train, X_test_cleaned, y_test)\n",
        "\n",
        "println(\"R² treino: \", result.r2_train, \" | R² teste: \", result.r2_test)\n",
        "println(\"RMSE treino: \", result.rmse_train, \" | RMSE teste: \", result.rmse_test)\n"
      ],
      "metadata": {
        "id": "zi61nGsQ6Okh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Julia",
      "name": "julia"
    },
    "nextjournal": {
      "nodes-edn": "{\"9d0873f8-5cc1-4c62-8a7c-60ca34c85d68\" {:output-log-lines {}, :language \"julia\", :id \"9d0873f8-5cc1-4c62-8a7c-60ca34c85d68\", :compute-ref #uuid \"4e2ebcb6-8cc2-499e-82fa-a768ec20c2b1\", :runtime [:runtime \"90436991-2923-44bb-b0d1-f235aec846ef\"], :kind \"code\", :error nil, :exec-duration 33810}, \"3e63395c-e74e-4f31-8f8a-f513fbe6a643\" {:id \"3e63395c-e74e-4f31-8f8a-f513fbe6a643\", :kind \"code\", :language \"julia\", :runtime [:runtime \"90436991-2923-44bb-b0d1-f235aec846ef\"], :error nil}, \"d3de8e74-90da-4c2d-9b07-b799fc9fa554\" {:output-log-lines {}, :language \"julia\", :id \"d3de8e74-90da-4c2d-9b07-b799fc9fa554\", :compute-ref #uuid \"ded55bec-391f-4f04-98a1-673b24ff9b83\", :runtime [:runtime \"90436991-2923-44bb-b0d1-f235aec846ef\"], :kind \"code\", :error nil, :exec-duration 15593}, \"e79ffdbe-e578-42eb-b82f-007b7a2d673f\" {:id \"e79ffdbe-e578-42eb-b82f-007b7a2d673f\", :kind \"code\", :language \"julia\", :runtime [:runtime \"90436991-2923-44bb-b0d1-f235aec846ef\"], :error nil, :compute-ref #uuid \"920952a5-ffbf-4d0a-9bc2-b872c7fc1bf0\", :exec-duration 4105, :output-log-lines {:stdout 1}}, \"9517f7d6-dca5-44fa-90c8-abe7cc4450f9\" {:id \"9517f7d6-dca5-44fa-90c8-abe7cc4450f9\", :kind \"code\", :language \"julia\", :runtime [:runtime \"90436991-2923-44bb-b0d1-f235aec846ef\"], :error nil, :compute-ref #uuid \"39525b5e-bff8-485d-9317-93aef9191b72\", :exec-duration 113, :output-log-lines {}}, \"e07a1bc3-5d72-4fbc-81fc-0d80008b0b41\" {:output-log-lines {}, :language \"julia\", :id \"e07a1bc3-5d72-4fbc-81fc-0d80008b0b41\", :compute-ref #uuid \"bb48829a-5640-4530-9e1e-a988f2ce9bb9\", :runtime [:runtime \"90436991-2923-44bb-b0d1-f235aec846ef\"], :kind \"code\", :error nil, :exec-duration 3876}, \"679b09f0-3896-4ec8-845e-fe5796d300c3\" {:output-log-lines {}, :language \"julia\", :id \"679b09f0-3896-4ec8-845e-fe5796d300c3\", :compute-ref #uuid \"4d3e225b-c8a4-4c96-be93-a23a9d0985a5\", :runtime [:runtime \"90436991-2923-44bb-b0d1-f235aec846ef\"], :kind \"code\", :error nil, :exec-duration 165}, \"67e2beb5-5eb6-47a7-a804-fbb4540d8d95\" {:output-log-lines {}, :language \"julia\", :id \"67e2beb5-5eb6-47a7-a804-fbb4540d8d95\", :compute-ref #uuid \"eba50ae4-2ab1-49a7-a24a-958d86ed4cef\", :runtime [:runtime \"90436991-2923-44bb-b0d1-f235aec846ef\"], :kind \"code\", :error nil, :exec-duration 2205}, \"90436991-2923-44bb-b0d1-f235aec846ef\" {:id \"90436991-2923-44bb-b0d1-f235aec846ef\", :kind \"runtime\", :environment [:environment {:article/nextjournal.id #uuid \"5b460d39-8c57-43a6-8b13-e217642b0146\", :change/nextjournal.id #uuid \"5fa43e2c-530b-4260-aab2-857bac98e540\", :node/id \"39e3f06d-60bf-4003-ae1a-62e835085aef\"}], :type :nextjournal, :language \"julia\", :output-log-lines nil, :compute-ref #uuid \"2f77defd-b4c4-4351-8b66-fd53b2b05887\", :error nil}, \"49ef1523-16b7-4bc4-ab8d-256b6df9b8ba\" {:output-log-lines {}, :language \"julia\", :id \"49ef1523-16b7-4bc4-ab8d-256b6df9b8ba\", :compute-ref #uuid \"e17b739b-b78e-4020-9fc8-2a84d468da0f\", :runtime [:runtime \"90436991-2923-44bb-b0d1-f235aec846ef\"], :kind \"code\", :error nil, :exec-duration 2053}, \"956f4a17-04de-438f-94ff-f2edfbf78b8c\" {:output-log-lines {}, :language \"julia\", :id \"956f4a17-04de-438f-94ff-f2edfbf78b8c\", :compute-ref #uuid \"f74ecb71-1dfd-45e3-b524-17c14129a295\", :runtime [:runtime \"90436991-2923-44bb-b0d1-f235aec846ef\"], :kind \"code\", :error nil, :exec-duration 2816}, \"fa7b715a-4d78-4a1e-9cf6-58accafb4289\" {:output-log-lines {}, :language \"julia\", :id \"fa7b715a-4d78-4a1e-9cf6-58accafb4289\", :compute-ref #uuid \"0d3b5157-7ac2-4880-841b-28155728f303\", :runtime [:runtime \"90436991-2923-44bb-b0d1-f235aec846ef\"], :kind \"code\", :error nil, :exec-duration 621}, \"a90472dc-e58d-4e46-b2bb-18eebec574bf\" {:content \"\\\"$VERSION\\\"\", :refs (), :output-log-lines {}, :language \"julia\", :id \"a90472dc-e58d-4e46-b2bb-18eebec574bf\", :compute-ref #uuid \"932bd74f-beb1-4148-a990-443dd4ee63d3\", :runtime [:runtime \"90436991-2923-44bb-b0d1-f235aec846ef\"], :kind \"code\", :error nil, :exec-duration 214, :bucket nil}}",
      "runtime-id": "90436991-2923-44bb-b0d1-f235aec846ef",
      "url": "https://nextjournal.com/a/UbmkHx8uZf1zhXg8MKbca"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}